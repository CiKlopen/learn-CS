# 操作系统的启动
 
    1. 计算机上电 bois启动 自检
    2. bois 搜索硬盘中的第一个扇区  512字节大小
    3. 将这512字节的代码与数据 加载到内存中
    4. bois将 cs:ip 指向0X7c000处
    5. 512字节代码 开始启动 自检  将setup system加载到内存中 注意加载的地址 cs：ip指向setuo
    6. setup被加载到内存后  主要功能为后续的system模块的启动做准备
    7. 配置gdt 将cpu切换到保护模式 
    8. 就是system模块

# 操作系统的进程
    0. 进程很重要，他是计算机中最小资源单位
    1. // 一个进程需要 cpu资源 内存资源 io资源 硬盘/磁盘资源   
    pcb
    tcb






# 系统调用
    1.为什么要讲系统调用
        1.1.操作系统在启动的时候，会设置特权级 将操作系统的内核设置为内核态，这就意味着，用户不能直接访问内核
        1.2 特权级 用户态 内核态
        1.3 一些内核级指令，与操作外部的硬件，设备，这些计算机底层的东西，或者说是可以影响到操作系统的稳定的指令，
            都需要到内核中去执行
        1.4 用户或者高级语言无法直接访问内核，那么如果想要操作内核比如向，在屏幕中打印一个hello world ，这个时候就需要进入内核，利用操作系统向上层提供的接口，
        进入内核
        1.5 进入内核的方法  中断 int 0x80  中断号 write read fork 中断表 table 中断调用 sys_call 中断调用返回 ret_sys_from_call
        1.6 
# 用户级线程 多线程
    为什么要多线程？
    资源 
    1.利用高级语言的多线程库来实现用户级线程的创建，
    2.相互之间不隔离，操作系统无法感知到用户线程
    3.用户级线程的切换，靠的是用户本身，或者线程库的规则
    4.创建与切换的开销小，不需要进入到内核
    5.靠切换用户栈来切换线程，

    缺点
        多个用户线程共用一个内核栈，如果其中一个线程进行系统调用，并阻塞，那么整个将不再占有cpu资源

    
    
    100:a(){            
        b();
        104:
    }
    200:b(){
        yield();
        204:
    }

---------------------  两个栈 yield负责切换pcb，根据tcb找到下个线程的用户栈，进行切换
                        保存状态，切换tcb，切换栈，根据 “}” 弹栈 弹出的是 用户栈和用户pc
    300:c(){            
        d();
        304:
    }
    400:d(){
        yield();
        404:
    }







# 内核级线程 
    0.  如果说用户级线程是栈到栈的切换，那么内核级线程就是 一套栈到一套栈的切换
    1.  线程切换，先切tcb 再从tcb中将内核栈的地址取出 切内核栈，取出新进程的状态，弹出保存在内核栈中的用户栈的栈地址，pc计数器，从而完成内核级线程的切换
    2.  


# 内核级线程的实现

    线程切换5段论
    1.fork进内核 
        sys_fork之后检查当前的pcb或者tcb中的字段，判断进程的状态是否需要调度
        
        switch_to(next)
            这里是利用、
                TSS任务段
                TR 任务寄存器
        切换的根本是:
                    先保存当前进程的状态，再加载下一个进程的状态，然后在切换
    1.  ret_sys_from_call   这个函数完成内核态到用户态的切换


# ThreadCreate
    ##进程的创建

    1. sys_fork
        push %gs
        ...
        pushl %eax
    
    2. call _copy_process   调用 copy这个函数   复制一个与父进程相同的子进程
    
    
    3. int copy_process(int nr,long ebp,long edi,long esi,long gs......)    这个函数传入的是 调用int 0x80之后，保存的用户态的状态   
        参数是通过栈传递的，用户态系统调用，保存状态到内核栈中，栈中参数传递给 copy用于创建进程
    
    4.  int copy_process(参数){  ////从左向右出栈  入栈自然就是从右向左入栈

        p = (struct task_struct *)get_free_page();  申请一段内存空间，用于创建pcb
            tsak_struct  这是pcb的结构体

        p->tss.esp0 = PAGE_SIZE + (long) p;
        p->tss.ss0 = 0x10;
         
        创建内核栈

        p->tss.ss = ss & 0xffff
        p->tss.esp = esp;

        创建用户栈(和父进程共用栈)
 

        1. 利用传进来的参数，创建pcb或者是tcb
        2. 在pcb也就是进程控制块中 创建或者叫初始化tss字段
        3. tss字段保存的就是 你传进来的父进程的状态
        
        p->tss.eip = eip;
        p->tss.cs = cs & 0xffff;

        将执行地址cs:eip放在tss中

        p->TSS.eax = 0; 区分父与子进程
        P->TSS.ecx = ecx
        P->TSS.ldt = _LDT(NR);
        
        在之后内存也要跟着切换

        p->state = TASK_RUNNING;

    }


    ····基本流程····

    申请内存空间
    创建TCB
    创建内核栈和用户栈

    填写两个stack   因为在这个架构中使用的是 tss来完成任务切换，状态保存在tss中，所以这个步骤这里省略

    关联栈和TCB

    父子用同一个用户栈，子进程再用pcb tss创建一个新的内核栈，内核栈独立才能使两个进程分开来


## shell
    int main(int argc,char*argv[])
    {
        
        
        while(1)  父进程无限循环
        {
            scanf("%s",cmd); 这里阻塞等待用户输入指令
            
            
            if(!fork())
            {
                exec(cmd);   子进程执行这里    

                子进程fork完毕之后，怎样去执行exec(ls)
                这时子进程将不能与父进程执行相同的代码
                如何改变子进程的执行代码
                    exec进到内核之后本质上是为了修改 内核栈中的ret 和 sp
                    在exec执行完毕后，内核转用户时 iret 弹出ls的执行地址 和用户栈


                _system_call:
                    push %ds .. %fs
                    pushl %edx..
                    call sys_execve
                
                _sys_execve:
                    lea EIP(%ESP),%eax
                    pushl %eax
                    call _do_execve
                
                int do_execve(* eip,... p+= change_ldt(...))
                    eip[0] = ex.a_entry;
                    eip[3]  = p;
                
                struct exec{
                    unsigned long a_magic;
                    unsigned a_entry;
                }


            }
            
            
            wait(0);         父进程等待子进程的执行完毕

        }

    
    
    
    }


# 执行fork
    fork(){
        mov %eax,_NR_fork
        INT 0x80   进入内核，那么下一句将会压栈
        mov res,%eax   如果是父进程 eax的值为子进程的pid   如果父进程阻塞，子进程返回 eax里为0
    }


··········


    1. 从用户栈到内核栈
    2. 内核栈找到TCB
    3. TCB用switch_to
    4. 完成TCB内核栈的切换
    5. iret完成内核栈到用户栈的切换 



    交替打印a b
        main()
        {
            if(!fork()){while(1)printf("A")}
            if(!fork()){while(1)printf("B")}
            wait();   父进程创建了这两个进程，之后wait函数阻塞，触发调度

                    system_call:
                        call sys_wait_waitpid

                    sys_waitpid()
                        current->state= TASK_INTERRUPTIBLI
                        schedule();

                        schedule(){
                            调度算法
                            
                            switch_to(next)

                        }
        }

    1. 先看fork  fork 
            mov _NR_FORK,%eax
            int 0x80     
                sys_call
                sys_fork
                copy_process  ret到 
                                    cmpl $0,state(current)
                                    jne reschedule
                                    iret

               进入系统调用，100处地址压栈 
        


        通过时钟中断完成 a到b的切换

        进程的创建  内核中完成 
        进程的切换 

        进程的执行函数 用户代码 
        
        
        
        
        100:mov %eax,res  如果是子进程执行200，如果不是执行208返回父进程
            cmpl res,0
            jne 208
        
        200:printf("A")
            jmp 200
        
        208:ret

        304: wait()
    2.
    3.
    4.
    5.



# CPU调度策略  
 ## 前台程序关注响应时间  后台任务关注周转时间
 ## io约束型   cpu约束型
 ## FIFO  
 1.  谁先进入，先调度谁:简单有效
 2.  一个只简单询问业务的人该怎么办
 3. 
    ## Priority

    1. 任务短可以适当优先


    ## 吞吐量
        响应时间越小，切换次数变多，系统内耗大，单位时间内执行的进程就小，吞吐量就小

    ## 到达时间  
        进程是按照它们到达的顺序被调度的。进程的到达时间决定了它在等待队列中的位置。
    
    ## CPU区间
        它表示一个任务执行所需的实际CPU时间

# 以轮转为核心，短作业优先，前台作业优先
    优先级队列调度
        前台任务 优先级高 需要响应时间 RR
        后台任务 优先级低 需要周转时间 SJF
        动态优先级提高，保证后台任务的执行
 # FCFC 先来先服务
 # SJF  短作业优先
 # 优先级调度
 # RR 轮转
 # MLFQ 多级反馈队列
 # SRTF 最短剩余时间优先
 # Fair 保证调度
 # 实时调度 

 # 一个实际的schedule函数
    schedule函数的本质工作是调度
    找到switch_to(next)中的next也是通过算法计算出的下一个要执行的进程
    1.静态优先级，动态优先级
    2.前台任务的优先级高，以时间片轮询来执行高优先级队列
    3.后台任务的优先级低，以短作业优先，加上时间片来执行低优先级队列

# 进程同步和信号量
 ## 多进程之间的临界区，共享资源，进程同步的目的就是维护多个进程的共同资源，在同一时间只能被一个进程访问，
        信号量和互斥锁都是为了完成进程同步的手段
    1. wakeup sleep queue等待队列

    struct semaphore
    {   
        int value;
        pcb *queue; 
    }
    P(semaphore s);
    V(semaphore s);


    P(semaphore s)
    {
        s.value--;

        if(s.value < 0){
            sleep(s.queue);
        }




    }
 ## 例子


1. **初始状态**：
   - `sem = 3`，表示有3个可用的资源。
   - 共有6个进程尝试访问这个资源。

2. **进程1、2、3访问资源**：
   - 进程1、2、3顺序执行`P`操作，每次执行都将`sem`减1。
   - 执行完这三次`P`操作后，`sem = 0`，表示当前没有剩余的资源。

3. **进程4、5、6尝试访问资源**：
   - 进程4、5、6继续执行`P`操作，因为`sem = 0`，它们不能立即获取资源，因此被放入等待队列，每次`P`操作都会使`sem`的值减1。
   - 执行完这三次`P`操作后，`sem = -3`，表示有3个进程在等待队列中等待资源。

4. **进程1、2、3中的任意一个释放资源**：
   - 假设进程1完成它的操作并执行`V`操作，这会使`sem`的值从-3增加到-2，并从等待队列中唤醒一个进程（比如进程4）来占用这个刚刚释放的资源。

5. **被唤醒的进程（进程4）执行操作**：
   - 进程4开始执行它的操作。完成后，进程4也会执行`V`操作，将`sem`的值从-2增加到-1，并可能唤醒等待队列中的下一个进程（比如进程5）。

6. **后续进程**：
   - 同样，当进程5和进程6被依次唤醒并完成它们的操作后，它们也会各自执行`V`操作，依次增加`sem`的值，并尝试从等待队列中唤醒其他等待的进程。

    总之，每当一个进程完成它的操作并执行`V`操作时，它不仅会释放一个资源（使`sem`的值增加），而且如果有进程在等待队列中，它还会导致系统从等待队列中唤醒一个进程。被唤醒的进程在完成其操作后，也应执行`V`操作，以保持资源管理的连续性和公平性。这个循环持续进行，直到所有进程都完成了它们的操作。


# 信号量临界区保护
  ## 防止进程间竞争信号量   原子操作
    什么是原子操作？
        特性：要么不执行，执行就会一次执行完毕，不可中断
  ## 临界区只能一个进程进入
  ## 读写信号量的代码必须是临界区

 ## 为什么要保护信号量 如何通过临界区保护信号量


 ## 进入临界区的方法   两个进程 Peterson算法 
        1. 轮转法  trun   互斥
        2. 标记法  flag   互斥
        3. 非对称标记 互斥 有空让进
        4. 进入临界区Peterson算法    结合轮转与标记
 ## 多个进程  面包店算法
              标记加轮转的我结合
        
        1. 如何轮转？ ，每个进程都获得一个序号，序号最小的进入
        2. 如何标记？ ，进程离开时序号为0，不为0的序号最小的进入

        总结: 1.先取号，将取号状态数组置为turn，取号号序数组取当前数组中的最大的号加一
              2.判断，for从0开始遍历 号序数组，用j表示，先判断当前j对应的状态数组是否在取号，如果在便while空转阻塞
              3.再判断，j是否不等于0，如果不等于0，且j比i小，那么while阻塞，因为是与逻辑，所以当不满足其中任一条件，那么将跳出while
              4.j=0 则表示当前j不想进入当前临界区 ， j比i大， 也会直接跳出，执行for循环
              5.进入完毕后，当前i就是其他进程中的j，所以将自身置为0，将进入临界区的权限让给后面的进程



        竞争条件: 和调度有关的共享数据语义错误
            错误由多个进程并发操作共享数据引起
            错误和调度顺序有关，难于发现和调试

        进入临界区 临界区 退出临界区      临界区是什么？    修改信号量的代码的地方就是临界区，要保护临界区，让信号量只能同时被一个进程所访问
        
        
        
 ## 基本原则: 互斥进入：如果一个进程在临界区中执行，则其他进程不允许进入
        1.互斥
            
                1.1 这些进程间的约束关系称为互斥(mutual exclusion)
                1.2 这保证了是临界区
        
        比较好的临界区保护原则

        2.有空让进
                2.1 若干进程要求进入空闲临界区时，应尽快使一进程进入临界区

        3.有限等待
                3.1 从进程发出进入请求到允许进入，不能无限等待

# 临界区保护的另一类解法...  硬件层次的执行  阻止调度 cli() sti()
    0. 出于速度的考虑，希望可以实现硬件层次的对临界区的保护，软件层次的实现，很复杂且执行效率不高
    1. 可以通过控制cpu的调度问题，就是当前进程进入临界区，那么就不让cpu去调度执行其他进程，等到当前进程退出临界区，cpu才可以调度
    2. cli sti 关中断防止cpu调度来实现 保护信号量，进行原子操作
 ## 临界区保护的硬件原子指令法 TestAndSet 函数  多CPU情况
    0.锁定 忙等待，释放锁
    1.testandset函数是原子操作，保证一个进程在查询锁变量的时候，另一个进程无法进行查询
    2.锁定 进入 如果lock=false 将lock赋值到rv lock=true  返回rv也就是旧值
    3.忙等待 如果lock=true，那么返回的也是true，while将会一直等待 直到lock=false
    4.释放锁 lock=false

        TestAndSet(boolean &x){
            boolean rv = x;
            x = true;
            return rv;
        }

        while(TestAndSet(&lock));
            临界区
        lock=false
            剩余区

 ## 二元信号量
    总结
        · 二元信号量（或互斥锁） 是特别设计用于互斥访问的，确保一次只有一个线程或进程可以访问共享资源。因此，它们在保护单个共享资源时非常有效。
        
        · 通用信号量 可以用于控制多个相同资源的访问，也可以用于进程或线程间的复杂同步。

        · 选择哪种类型的信号量取决于你的具体需求：如果你需要保护的资源只有一个实例，或者你需要确保代码块在任何时刻只被一个线程执行，二元信号量或互斥锁是更好的选择。如果你需要管理多个资源的可用性或实现复杂的同步模式，通用信号量可能更适合。


# 信号量的代码实现
    0.  读磁盘，首先获取一个内存缓冲区
    1.  启动读磁盘后进程将阻塞  
    2.
    3.
    4.

# 死锁的形成
    形成死锁的4个必要条件
        1.互斥使用
            资源的固有特性
        2.不可抢占
            资源只能自愿放弃，如车开走之后
        3.占有并等待
            进程必须占有资源，再去申请
        4.循环等待
            在资源分配图中存在一个环路 
 ## 死锁处理方法概述
        1.死锁预防 
            破坏死锁出现的条件
        2.死锁避免
            检查每个资源请求，如果造成死锁就拒绝
        3.死锁检测+恢复
            检测到死锁出现时，让一些进程回滚，让出资源
        4.死锁忽略
            就好像没有死锁一样
 ## 死锁预防的方法例子
        1.在进程执行前，一次性申请所有需要的资源，不会占有资源再去申请其他资源
            缺点1: 需要预知未来，编程困难
            缺点2: 许多资源分配后很长时间后才使用，资源利用率低下
        
        2.对资源类型进行排序，资源申请必须按序进行，不会出现环路等待
            缺点: 仍然造成资源浪费
 ## 死锁避免 ： 判断此次请求是否引起死锁？
        1.如果系统中的所有进程存在一个可完成的执行序列pn。。。。。。，则称系统处于安全状态




# 内存管理
 ## 内存段
    物理地址
    逻辑地址
    偏移地址
    基地址

    动态重定位
    静态重定位

    编译时重定位
    载入时重定位
    运行时重定位
    
    GDT
    LDT
    PCB 
    
    我的理解：
        每个进程都有LDT PCB 
        LDT表可以帮助实现程序运行时的动态重定位
            LDT表中存储各段的物理基地址，方便与程序时的逻辑地址进行地址处理
        PCB中存储着LDT表的位置
 ## 内存分区和分页
    
    1.找出空闲内存分区
    2.将程序读入空闲内存
    3.建立地址映射表，LDT
 ## 固定分区
    一个面包，多个孩子分
        1.等分   操作系统初始化时将内存等分成K个分区
        2.       但孩纸有大有小，段也有大有小，需求不一定

 ## 可变分区
    存在内存碎片



    首先适配
    最佳适配
    最差适配

    维护一个内存表 起始地址与长度
 ## 内存分页
    0. 用户希望分段，分段内存的碎片过多
    0. 内存希望分页，分页可以减少内存的浪费
    0. 段通过页的方式打散
    1. 将内存分成页
    2. 针对每个段内存请求，系统一页一页的分配给给这个段


    我的理解，
        概念   虚拟页号对应物理页号     物理页号可以计算出基地址，   物理页号 * 页大小 = 基地址  而 基地址 + 偏移地址 = 物理地址
        
        这保证了内存的充分利用，减少碎片化，每个段可以保存在不连续的页上，在虚拟页上是连续的就行。 

    重点  应用只知道虚拟地址，   通过虚拟地址 中间加上mmu去找物理地址 
        ChatGPT ：
                    应用只知道有虚拟地址，虚拟地址上是连续的，但是物理地址上可能是分散的，内存的页机制将内存划分为指定大小的块，目的是为了提高 内存的使用效率，减少内存碎片，为了使操作系统可以更加高效的利用内存，引入虚拟内存，原来是给应用程序分配物理地址，现在是给应用程序分配虚拟地址，这个分配是运行时动态重定位，虚拟地址可以不直接对应物理地址，寻址时通过页表找到映射的地址，其实最后也是基地址加上偏移地址

                    您的总结是准确的，正确地概述了虚拟内存系统的关键原理。如果要进一步精细化或指出常见的误解，可以注意以下几点，但这些并不意味着您的总结有错误：

                        虚拟内存的大小：
                            
                                虚拟内存的大小通常远大于物理内存，这是通过操作系统的管理和硬盘上的交换空间来实现的。这个细节有助于理解为什么可以运行多个大型应用程序，即使物理RAM有限。

                        页表的作用：
                            
                                页表不仅仅是进行基地址加上偏移地址的简单计算，它还涉及到权限检查、是否在物理内存中以及是否需要从硬盘调入内存等复杂过程。

                        内存分配的动态性：
                                
                                虚拟地址到物理地址的映射不是静态的，而是可以动态改变的。这意味着运行时可以根据需要加载或卸载页面，或者在物理内存不足时将页面交换到硬盘上。

                        内存碎片的类型：
                        
                                虽然页机制确实减少了外部碎片，但内部碎片依然存在，因为页的固定大小可能导致每个页的部分空间未被充分利用。

                    您的总结很好地抓住了虚拟内存管理的关键概念，包括虚拟地址和物理地址的映射、动态重定位、页表的作用，以及内存页机制如何提高内存使用效率和减少碎片。每个概念都是为了解决特定的问题或优化计算机系统的性能。

# 多级页表和快表
    课前预习：    
        
        多级页表   单级页表可以称为一个块，为了使内存碎片的减少，块越小越好，通常为4K，但是伴随的问题是，页表就会过大，这是一个成反比的问题
                   块小页大   但是如果仅仅是为了将页变
        快表

        分页机制   页表占用内存的大小   页表项的个数   一个页表项占用4-8个字节
    
    页号 = 地址 % 页大小  = 商 是页号  余数是偏移量

 ## 第一种尝试，只存放用到的页
    
    1. 只有用到的逻辑页才有页表项

        问题 
            1. 页表中的页号不连续，就需要比较，查找，折半

        结论
            2. 32位地址空间  +  4k页面  +  页号必须连续 = 2的20次方个页表项 = 大页表占用内存，造成浪费
 ## 多级页表
    为了保证地址空间的连续，减少内存空间的浪费

    1. 书的章节 小节  顺序查找   根据大章快速查找小节再查找页

    2. 多级页表提高了空间的利用率，多级页表每增加一级就会在查询时增加一次查询

 ## TLB 快表
    弥补多级页表在时间上的浪费

    1. TLB 是一组相联快速存储，是寄存器      一个有记忆的地址转换寄存器
        
        这个寄存器与多级页表相配合，取长补短

        将最近访问的逻辑页与物理页的对应关系存放在TLB中   

 ## TLB 命中率
    
    TLB 命中时效率会很高，未命中时效率降低  

    程序地址访问存在局部性

    空间局部性

# 段页结合的实际内存管理

    段做虚拟地址
    页做物理地址

# 内存换入换出

    评价准则: 缺页次数

  换入
    1. 申请空闲内存页
    2. 从磁盘调入页
    3. 创建映射表

    为了实现虚拟地址
        店铺与仓库的关系 可以使用更大的内存
  换出
        并不是总是获得新的页，内存是有限的
            需要淘汰一页，换出到磁盘，选择哪一页换出？
            
            page = get_free_page();  //获取一个空闲页
            bread_page(page,current->executable->i_dev,nr);   将调入页放入空闲页
    
    1.  FIFO,MIN,LRU 换出页的算法，换谁出去？  页面置换算法
            实例:
                3个页框，
                顺序    A B C A B D A D B C B
        FIFO
            先入先出，共有7次缺页
        
        MIN
            最优算法，5次缺页

            但是需要知道将来发生的事...
        
        LRU 页面置换算法   准确实现难，近似实现才是王道

            用过去的历史预测将来。LRU算法: 选最近最长一段时间没有使用的页淘汰(最近最少使用的)
            将过去使用最少的页进行淘汰。

            利用程序的局部性

            实现方法：每页维护一个时间戳(time stamp)
                        浪费cpu资源，每执行一条指令都需要去维护对应的页表
                      
                      页码栈
                        
                      LRU近似实现-将时间计数变为是和否
                        每个页加一个引用位(reference bit)

                            每次访问一页时，硬件自动设置该位
                            选择淘汰页: 扫描该位，是1时清0，并继续扫描；是0时淘汰该页
                        Clock算法
                            引入R位，每个表如果被使用 将r位置1
                            
                            clock双指针，一个定时清楚r位，一个是淘汰指针
        
        置换策略有了，还需要解决一个问题
            给进程分配多少个页框
                分配的多，请求调页导致的内存高效利用就没用了
            分配的太少会导致颠簸
                颠簸，在磁盘与内存中频繁的调页，缺页调页
            
            解释：  
                系统内进程增多-》每个进程的缺页率增大-》缺页率增大到一定程度，进程总等待调页完成-》
                CPU利用率降低-》进程进一步增多，缺页率更大...
                
                为了防止颠簸
                    检测到缺页多了，就给进程多分配几个页框，覆盖住进程的频繁调用局部，防止进程频繁缺页，调页，导致系统颠簸
                

        总结：
                0. swap分区  swap_in swap_out   do_no_page

                1.访问地址发现缺页，触发缺页中断，从磁盘中读入页放入内存，更新映射表
                2.在放入的时候，可能会页框不足，此时调用clock算法淘汰一个不常使用的页，以放入现在需要的页
                3.实现swap分区是为了实现虚拟内存，实现虚拟内存是为了实现段页机制，实现段页机制是为了实现内存管理为了载入程序，实现进程管理，从而实现多进程管理

# I/O与显示器
    0. printf(Display)  


    1. 向外设控制器发送指令，外设去做事情，CPU继续执行其他指令
        CPU向控制器中的寄存器读写数据
    2. 外设处理完毕后向CPU发出中断，CPU进行中断处理
        控制器完成过真正的工作，并向CPU发中断信号
    3. 需要查寄存器地址，内容的格式和语义...操作系统要给用户提供一个简单视图--文件视图

    4. 形成文件视图，发出out指令，形成中断处理
实际:
    一段操纵外设的程序

        int fd = open("/dev/xxx");
        for (int i = 0; i <10; i++>){
            write(fd,i,sizeof(int))
        }
        close(fd);

        1.不论设备都是    open,read,write,close  操作系统为用户提供统一的接口

        2.不同的设备对应不同的设备文件(/dev/xxx)
            根据设备文件找到控制器的地址，内容格式等等
        
        1.通过out指令向外部发送命令
        2.通过文件形成统一的文件视图
        3.中断处理

            1. 程序启动时，操作系统为每个进程创建三个标准的文件描述符：标准输入(0)，标准输出(1)，和标准错误(2)。这些文件描述符默认是打开的，所以通常不需要你在写数据到标准输出之前手动调用open。

            2. 调用printf时，它会构造格式化字符串，然后它将这个字符串传递给底层的write函数来实际执行写操作。write函数需要一个文件描述符来知道数据应该写到哪里。对于printf，这通常是标准输出，即文件描述符1。

            3. 文件描述符表 (filp)：每个进程有自己的文件描述符表。这个表是在进程控制块（例如在Linux中是task_struct）中，并且current指针指向当前正在运行的进程的控制块。

            4. 文件描述符 (fd)：这是一个索引，指向进程文件描述符表中的条目。对于printf和其他写入到标准输出的函数，这个索引是1。

            5. 检索文件信息：当内核执行如write这样的系统调用时，它会使用current->filp[fd]来查找文件描述符fd对应的文件信息结构（如file结构）。然后使用这个信息来进行写操作。

            6. 所以，printf实际上是依赖于程序启动时就已经打开并分配给进程的标准输出文件描述符。file = current->filp[fd]这行代码在write系统调用的上下文中被用到，以获取与文件描述符fd相关联的文件的详细信息，不过对于printf，这个fd几乎总是指向标准输出。

# 键盘 (output 输入)
    1. 按下键盘触发中断
    2. 中断例程取出键盘扫描码
    3. 根据扫描码得到ASCII码
    4. 然后进行响应的处理程序


# 生磁盘的使用

    1. 盘面 磁道 扇区
    2. 移动磁头到相应的磁道上，旋转磁盘到相应的扇区上，然后进行读写，原理是   磁生电，电生磁
       控制器 寻道 旋转 传输
    3. 需要告诉控制器 写柱面 磁头 扇区 缓存位置
    4. 总线盗用技术，将磁盘上的数据读入到内存中 
 
 1. 通过盘块号读写磁盘(一层抽象)
 2. 磁盘驱动负责从block计算出cyl，head，sec(CHS)
  
  如何编制？
    磁盘访问时间 = 写入控制时间+寻道时间+旋转时间+传输时间  
  空间换时间
    分块机制，浪费一点空间，来节省寻道时间
    每次读写1k，碎片0.5k;读写速度100k/秒
    每次读写1m: 碎片0.5m；读写速度约40m/秒
    
    上层应用从读写一个扇区到读写一个盘块，一个盘块是多个连续的扇区，浪费一点磁盘空间，来换时间
 
 2. 多个进程通过队列使用磁盘(第二层抽象)
 3. 多个磁盘访问请求出现在请求队列怎么办？
  4. 调度的目标是什么？ 调度时主要考察什么？
    目标是平均访问延时小  寻道时间是主要矛盾
    所以引入调度算法，仍然从FCFS开始  先来先服务
    SSTF 短寻道优先 
    缺点： 容易导致远的柱面饥饿问题，如果有一个读写频繁的进程，一直在几个近的块进行读写，那么磁头将不会去较远的柱面去读写
    SCAN 扫描调度   SSTF + 中途不回折：每个请求都有处理机会

    1. 进程“得到盘块号”，算出扇区号(sector)
    2. 用扇区号make req，用电梯算法add_request
    3. 进程sleep_on
    4. 磁盘中断处理

# 从生磁盘到文件
   引入文件，对磁盘使用的第三层抽象

   1.   让普通用户使用raw disk: 许多人连扇区都不知道是什么？ 要求他们根据盘块号来访问磁盘....
   2.   需要在盘块上引入更高一层次的抽象概念! 文件
   3.   文件: 建立字符流到盘块集合的映射
   4.   根据文件名找到FCB文件控制块，
   5.   起始块，块数
   6.   要修改的位置 % 块大小 + 起始块 = 定位到要修改的块

   连续结构适合存放字典这种不会改动的数据
   链式结构的灵活性非常强
   索引结构  多级索引  
    2级索引 每个表项对应一个1级索引表项  1级索引表项里存放块的映射
     可以表示很大的文件
     很小的文件高效访问
     中等大小的文件访问速度也不慢

# 文件使用磁盘的实现
    sys_write(fd) 传入文件标识符 数据缓冲区 字节长度
    {
        struct file *file = current->filp[fd]   当前进程打开了一个文件，并且将当前进程已经打开的文件描述符表中 取出对应的file结构体
        struct m_inode *inode = file->inode     file结构体中找到inode数据
        
        1. file： 指向内核中表示已打开文件的 data 结构的指针。它可能指向类似于 struct file 的结构，该结构保存有关已打开文件的信息。
        2. current： 指当前运行的进程。在内核中，每个进程都有自己的上下文，包括有关已打开文件的信息。
        3. filp： 指向 struct file 结构的数组。数组中的每个元素对应于当前进程的文件描述符。
        4. fd： 代表文件描述符的整数。它用作 filp 数组的索引。
    }

    根据文件名，找inode，根据inode找对应的数据块，

# 目录与文件系统
    第四层抽象 文件系统，抽象整个磁盘    树状 目录
    笔记   
    1. 之前是根据一个文件的fcb去找对应的数据块，chs，现在是通过目录去找
    2. 磁盘文件: 建立了字符流到盘块集合的映射关系
    3. 在其他计算机上：应用结构+存储的数据可以得到那棵文件树，找到文件，读写文件.....
    4. 接上，得到文件名，就能找到FCB，得到FCB，就能找到块，得到块，就能计算出扇区位置，然后将这个放入到等待队列，等待被执行，有CHS就能去驱动磁盘
    5. 根据路径名找到FCB  这是第四层抽象要做的事情
    6. 磁盘格局  引导块  
                 超级块存放节点位图 盘块位图的大小，记录两个位图的大小
                 inode位图 哪些inode空闲，哪些占用
                 盘块位图  哪些盘块空闲，硬盘大小不同这个位图的大小也不同

# 目录解析代码实现
    1.  从open解释 如何去实现目录
        根据你的文件路径去找你要的文件
        你当前的进程的父进程拥有根目录的inode，所以可以找到根目录，再根据根目录一级一级向下去查找，其目的是找到你的文件的inode
        目录也是文件，其中inode存放的是，下级目录的字符串和inode编号
        根目录的地址和inode会在在硬盘启动的时候被载入到 inode数组中的第0个位置 同时呢在shell启动的时候会放到shell的pcb中的文件描述表



    2.操作系统全图
        操作系统是管理硬件的软件，首先管理CPU
        


     
