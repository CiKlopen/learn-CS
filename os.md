# 操作系统的启动
 
    1. 计算机上电 bois启动 自检
    2. bois 搜索硬盘中的第一个扇区  512字节大小
    3. 将这512字节的代码与数据 加载到内存中
    4. bois将 cs:ip 指向0X7c000处
    5. 512字节代码 开始启动 自检  将setup system加载到内存中 注意加载的地址 cs：ip指向setuo
    6. setup被加载到内存后  主要功能为后续的system模块的启动做准备
    7. 配置gdt 将cpu切换到保护模式 
    8. 就是system模块

# 操作系统的进程
    0. 进程很重要，他是计算机中最小资源单位
    1. // 一个进程需要 cpu资源 内存资源 io资源 硬盘/磁盘资源   
    pcb
    tcb






# 系统调用
    1.为什么要讲系统调用
        1.1.操作系统在启动的时候，会设置特权级 将操作系统的内核设置为内核态，这就意味着，用户不能直接访问内核
        1.2 特权级 用户态 内核态
        1.3 一些内核级指令，与操作外部的硬件，设备，这些计算机底层的东西，或者说是可以影响到操作系统的稳定的指令，
            都需要到内核中去执行
        1.4 用户或者高级语言无法直接访问内核，那么如果想要操作内核比如向，在屏幕中打印一个hello world ，这个时候就需要进入内核，利用操作系统向上层提供的接口，
        进入内核
        1.5 进入内核的方法  中断 int 0x80  中断号 write read fork 中断表 table 中断调用 sys_call 中断调用返回 ret_sys_from_call
        1.6 
# 用户级线程 多线程
    为什么要多线程？
    资源 
    1.利用高级语言的多线程库来实现用户级线程的创建，
    2.相互之间不隔离，操作系统无法感知到用户线程
    3.用户级线程的切换，靠的是用户本身，或者线程库的规则
    4.创建与切换的开销小，不需要进入到内核
    5.靠切换用户栈来切换线程，

    缺点
        多个用户线程共用一个内核栈，如果其中一个线程进行系统调用，并阻塞，那么整个将不再占有cpu资源

    
    
    100:a(){            
        b();
        104:
    }
    200:b(){
        yield();
        204:
    }

---------------------  两个栈 yield负责切换pcb，根据tcb找到下个线程的用户栈，进行切换
                        保存状态，切换tcb，切换栈，根据 “}” 弹栈 弹出的是 用户栈和用户pc
    300:c(){            
        d();
        304:
    }
    400:d(){
        yield();
        404:
    }







# 内核级线程 
    0.  如果说用户级线程是栈到栈的切换，那么内核级线程就是 一套栈到一套栈的切换
    1.  线程切换，先切tcb 再从tcb中将内核栈的地址取出 切内核栈，取出新进程的状态，弹出保存在内核栈中的用户栈的栈地址，pc计数器，从而完成内核级线程的切换
    2.  


# 内核级线程的实现

    线程切换5段论
    1.fork进内核 
        sys_fork之后检查当前的pcb或者tcb中的字段，判断进程的状态是否需要调度
        
        switch_to(next)
            这里是利用、
                TSS任务段
                TR 任务寄存器
        切换的根本是:
                    先保存当前进程的状态，再加载下一个进程的状态，然后在切换
    1.  ret_sys_from_call   这个函数完成内核态到用户态的切换


# ThreadCreate
    ##进程的创建

    1. sys_fork
        push %gs
        ...
        pushl %eax
    
    2. call _copy_process   调用 copy这个函数   复制一个与父进程相同的子进程
    
    
    3. int copy_process(int nr,long ebp,long edi,long esi,long gs......)    这个函数传入的是 调用int 0x80之后，保存的用户态的状态   
        参数是通过栈传递的，用户态系统调用，保存状态到内核栈中，栈中参数传递给 copy用于创建进程
    
    4.  int copy_process(参数){  ////从左向右出栈  入栈自然就是从右向左入栈

        p = (struct task_struct *)get_free_page();  申请一段内存空间，用于创建pcb
            tsak_struct  这是pcb的结构体

        p->tss.esp0 = PAGE_SIZE + (long) p;
        p->tss.ss0 = 0x10;
         
        创建内核栈

        p->tss.ss = ss & 0xffff
        p->tss.esp = esp;

        创建用户栈(和父进程共用栈)
 

        1. 利用传进来的参数，创建pcb或者是tcb
        2. 在pcb也就是进程控制块中 创建或者叫初始化tss字段
        3. tss字段保存的就是 你传进来的父进程的状态
        
        p->tss.eip = eip;
        p->tss.cs = cs & 0xffff;

        将执行地址cs:eip放在tss中

        p->TSS.eax = 0; 区分父与子进程
        P->TSS.ecx = ecx
        P->TSS.ldt = _LDT(NR);
        
        在之后内存也要跟着切换

        p->state = TASK_RUNNING;

    }


    ····基本流程····

    申请内存空间
    创建TCB
    创建内核栈和用户栈

    填写两个stack   因为在这个架构中使用的是 tss来完成任务切换，状态保存在tss中，所以这个步骤这里省略

    关联栈和TCB

    父子用同一个用户栈，子进程再用pcb tss创建一个新的内核栈，内核栈独立才能使两个进程分开来


## shell
    int main(int argc,char*argv[])
    {
        
        
        while(1)  父进程无限循环
        {
            scanf("%s",cmd); 这里阻塞等待用户输入指令
            
            
            if(!fork())
            {
                exec(cmd);   子进程执行这里    

                子进程fork完毕之后，怎样去执行exec(ls)
                这时子进程将不能与父进程执行相同的代码
                如何改变子进程的执行代码
                    exec进到内核之后本质上是为了修改 内核栈中的ret 和 sp
                    在exec执行完毕后，内核转用户时 iret 弹出ls的执行地址 和用户栈


                _system_call:
                    push %ds .. %fs
                    pushl %edx..
                    call sys_execve
                
                _sys_execve:
                    lea EIP(%ESP),%eax
                    pushl %eax
                    call _do_execve
                
                int do_execve(* eip,... p+= change_ldt(...))
                    eip[0] = ex.a_entry;
                    eip[3]  = p;
                
                struct exec{
                    unsigned long a_magic;
                    unsigned a_entry;
                }


            }
            
            
            wait(0);         父进程等待子进程的执行完毕

        }

    
    
    
    }


# 执行fork
    fork(){
        mov %eax,_NR_fork
        INT 0x80   进入内核，那么下一句将会压栈
        mov res,%eax   如果是父进程 eax的值为子进程的pid   如果父进程阻塞，子进程返回 eax里为0
    }


··········


    1. 从用户栈到内核栈
    2. 内核栈找到TCB
    3. TCB用switch_to
    4. 完成TCB内核栈的切换
    5. iret完成内核栈到用户栈的切换 



    交替打印a b
        main()
        {
            if(!fork()){while(1)printf("A")}
            if(!fork()){while(1)printf("B")}
            wait();   父进程创建了这两个进程，之后wait函数阻塞，触发调度

                    system_call:
                        call sys_wait_waitpid

                    sys_waitpid()
                        current->state= TASK_INTERRUPTIBLI
                        schedule();

                        schedule(){
                            调度算法
                            
                            switch_to(next)

                        }
        }

    1. 先看fork  fork 
            mov _NR_FORK,%eax
            int 0x80     
                sys_call
                sys_fork
                copy_process  ret到 
                                    cmpl $0,state(current)
                                    jne reschedule
                                    iret

               进入系统调用，100处地址压栈 
        


        通过时钟中断完成 a到b的切换

        进程的创建  内核中完成 
        进程的切换 

        进程的执行函数 用户代码 
        
        
        
        
        100:mov %eax,res  如果是子进程执行200，如果不是执行208返回父进程
            cmpl res,0
            jne 208
        
        200:printf("A")
            jmp 200
        
        208:ret

        304: wait()
    2.
    3.
    4.
    5.



# CPU调度策略  
 ## 前台程序关注响应时间  后台任务关注周转时间
 ## io约束型   cpu约束型
 ## FIFO  
 1.  谁先进入，先调度谁:简单有效
 2.  一个只简单询问业务的人该怎么办
 3. 
    ## Priority

    1. 任务短可以适当优先


    ## 吞吐量
        响应时间越小，切换次数变多，系统内耗大，单位时间内执行的进程就小，吞吐量就小

    ## 到达时间  
        进程是按照它们到达的顺序被调度的。进程的到达时间决定了它在等待队列中的位置。
    
    ## CPU区间
        它表示一个任务执行所需的实际CPU时间

# 以轮转为核心，短作业优先，前台作业优先
    优先级队列调度
        前台任务 优先级高 需要响应时间 RR
        后台任务 优先级低 需要周转时间 SJF
        动态优先级提高，保证后台任务的执行
 # FCFC 先来先服务
 # SJF  短作业优先
 # 优先级调度
 # RR 轮转
 # MLFQ 多级反馈队列
 # SRTF 最短剩余时间优先
 # Fair 保证调度
 # 实时调度 

 # 一个实际的schedule函数
    schedule函数的本质工作是调度
    找到switch_to(next)中的next也是通过算法计算出的下一个要执行的进程
    1.静态优先级，动态优先级
    2.前台任务的优先级高，以时间片轮询来执行高优先级队列
    3.后台任务的优先级低，以短作业优先，加上时间片来执行低优先级队列

# 进程同步和信号量
 ## 多进程之间的临界区，共享资源，进程同步的目的就是维护多个进程的共同资源，在同一时间只能被一个进程访问，
        信号量和互斥锁都是为了完成进程同步的手段
    1. wakeup sleep queue等待队列

    struct semaphore
    {   
        int value;
        pcb *queue; 
    }
    P(semaphore s);
    V(semaphore s);


    P(semaphore s)
    {
        s.value--;

        if(s.value < 0){
            sleep(s.queue);
        }




    }
 ## 例子


1. **初始状态**：
   - `sem = 3`，表示有3个可用的资源。
   - 共有6个进程尝试访问这个资源。

2. **进程1、2、3访问资源**：
   - 进程1、2、3顺序执行`P`操作，每次执行都将`sem`减1。
   - 执行完这三次`P`操作后，`sem = 0`，表示当前没有剩余的资源。

3. **进程4、5、6尝试访问资源**：
   - 进程4、5、6继续执行`P`操作，因为`sem = 0`，它们不能立即获取资源，因此被放入等待队列，每次`P`操作都会使`sem`的值减1。
   - 执行完这三次`P`操作后，`sem = -3`，表示有3个进程在等待队列中等待资源。

4. **进程1、2、3中的任意一个释放资源**：
   - 假设进程1完成它的操作并执行`V`操作，这会使`sem`的值从-3增加到-2，并从等待队列中唤醒一个进程（比如进程4）来占用这个刚刚释放的资源。

5. **被唤醒的进程（进程4）执行操作**：
   - 进程4开始执行它的操作。完成后，进程4也会执行`V`操作，将`sem`的值从-2增加到-1，并可能唤醒等待队列中的下一个进程（比如进程5）。

6. **后续进程**：
   - 同样，当进程5和进程6被依次唤醒并完成它们的操作后，它们也会各自执行`V`操作，依次增加`sem`的值，并尝试从等待队列中唤醒其他等待的进程。

    总之，每当一个进程完成它的操作并执行`V`操作时，它不仅会释放一个资源（使`sem`的值增加），而且如果有进程在等待队列中，它还会导致系统从等待队列中唤醒一个进程。被唤醒的进程在完成其操作后，也应执行`V`操作，以保持资源管理的连续性和公平性。这个循环持续进行，直到所有进程都完成了它们的操作。


# 信号量临界区保护
  ## 防止进程间竞争信号量   原子操作
    什么是原子操作？
        特性：要么不执行，执行就会一次执行完毕，不可中断
  ## 临界区只能一个进程进入
  ## 读写信号量的代码必须是临界区

 ## 为什么要保护信号量 如何通过临界区保护信号量


 ## 进入临界区的方法   两个进程 Peterson算法 
        1. 轮转法  trun   互斥
        2. 标记法  flag   互斥
        3. 非对称标记 互斥 有空让进
        4. 进入临界区Peterson算法    结合轮转与标记
 ## 多个进程  面包店算法
              标记加轮转的我结合
        
        1. 如何轮转？ ，每个进程都获得一个序号，序号最小的进入
        2. 如何标记？ ，进程离开时序号为0，不为0的序号最小的进入

        总结: 1.先取号，将取号状态数组置为turn，取号号序数组取当前数组中的最大的号加一
              2.判断，for从0开始遍历 号序数组，用j表示，先判断当前j对应的状态数组是否在取号，如果在便while空转阻塞
              3.再判断，j是否不等于0，如果不等于0，且j比i小，那么while阻塞，因为是与逻辑，所以当不满足其中任一条件，那么将跳出while
              4.j=0 则表示当前j不想进入当前临界区 ， j比i大， 也会直接跳出，执行for循环
              5.进入完毕后，当前i就是其他进程中的j，所以将自身置为0，将进入临界区的权限让给后面的进程



        竞争条件: 和调度有关的共享数据语义错误
            错误由多个进程并发操作共享数据引起
            错误和调度顺序有关，难于发现和调试

        进入临界区 临界区 退出临界区      临界区是什么？    修改信号量的代码的地方就是临界区，要保护临界区，让信号量只能同时被一个进程所访问
        
        
        
 ## 基本原则: 互斥进入：如果一个进程在临界区中执行，则其他进程不允许进入
        1.互斥
            
                1.1 这些进程间的约束关系称为互斥(mutual exclusion)
                1.2 这保证了是临界区
        
        比较好的临界区保护原则

        2.有空让进
                2.1 若干进程要求进入空闲临界区时，应尽快使一进程进入临界区

        3.有限等待
                3.1 从进程发出进入请求到允许进入，不能无限等待

# 临界区保护的另一类解法...  硬件层次的执行  阻止调度 cli() sti()
    0. 出于速度的考虑，希望可以实现硬件层次的对临界区的保护，软件层次的实现，很复杂且执行效率不高
    1. 可以通过控制cpu的调度问题，就是当前进程进入临界区，那么就不让cpu去调度执行其他进程，等到当前进程退出临界区，cpu才可以调度
    2. cli sti 关中断防止cpu调度来实现 保护信号量，进行原子操作
 ## 临界区保护的硬件原子指令法 TestAndSet 函数  多CPU情况
    0.锁定 忙等待，释放锁
    1.testandset函数是原子操作，保证一个进程在查询锁变量的时候，另一个进程无法进行查询
    2.锁定 进入 如果lock=false 将lock赋值到rv lock=true  返回rv也就是旧值
    3.忙等待 如果lock=true，那么返回的也是true，while将会一直等待 直到lock=false
    4.释放锁 lock=false

        TestAndSet(boolean &x){
            boolean rv = x;
            x = true;
            return rv;
        }

        while(TestAndSet(&lock));
            临界区
        lock=false
            剩余区

 ## 二元信号量
    总结
        · 二元信号量（或互斥锁） 是特别设计用于互斥访问的，确保一次只有一个线程或进程可以访问共享资源。因此，它们在保护单个共享资源时非常有效。
        
        · 通用信号量 可以用于控制多个相同资源的访问，也可以用于进程或线程间的复杂同步。

        · 选择哪种类型的信号量取决于你的具体需求：如果你需要保护的资源只有一个实例，或者你需要确保代码块在任何时刻只被一个线程执行，二元信号量或互斥锁是更好的选择。如果你需要管理多个资源的可用性或实现复杂的同步模式，通用信号量可能更适合。


# 信号量的代码实现
    0.  读磁盘，首先获取一个内存缓冲区
    1.  启动读磁盘后进程将阻塞  
    2.
    3.
    4.

# 死锁的形成
    形成死锁的4个必要条件
        1.互斥使用
            资源的固有特性
        2.不可抢占
            资源只能自愿放弃，如车开走之后
        3.占有并等待
            进程必须占有资源，再去申请
        4.循环等待
            在资源分配图中存在一个环路 
 ## 死锁处理方法概述
        1.死锁预防 
            破坏死锁出现的条件
        2.死锁避免
            检查每个资源请求，如果造成死锁就拒绝
        3.死锁检测+恢复
            检测到死锁出现时，让一些进程回滚，让出资源
        4.死锁忽略
            就好像没有死锁一样
 ## 死锁预防的方法例子
        1.在进程执行前，一次性申请所有需要的资源，不会占有资源再去申请其他资源
            缺点1: 需要预知未来，编程困难
            缺点2: 许多资源分配后很长时间后才使用，资源利用率低下
        
        2.对资源类型进行排序，资源申请必须按序进行，不会出现环路等待
            缺点: 仍然造成资源浪费
 ## 死锁避免 ： 判断此次请求是否引起死锁？
        1.如果系统中的所有进程存在一个可完成的执行序列pn。。。。。。，则称系统处于安全状态




# 内存管理
 ## 内存段
    物理地址
    逻辑地址
    偏移地址
    基地址

    动态重定位
    静态重定位

    编译时重定位
    载入时重定位
    运行时重定位
    
    GDT
    LDT
    PCB 
    
    我的理解：
        每个进程都有LDT PCB 
        LDT表可以帮助实现程序运行时的动态重定位
            LDT表中存储各段的物理基地址，方便与程序时的逻辑地址进行地址处理
        PCB中存储着LDT表的位置
 ## 内存分区和分页
    
    1.找出空闲内存分区
    2.将程序读入空闲内存
    3.建立地址映射表，LDT
 ## 固定分区
    一个面包，多个孩子分
        1.等分   操作系统初始化时将内存等分成K个分区
        2.       但孩纸有大有小，段也有大有小，需求不一定

 ## 可变分区
    存在内存碎片



    首先适配
    最佳适配
    最差适配

    维护一个内存表 起始地址与长度
 ## 内存分页
    0. 用户希望分段，分段内存的碎片过多
    0. 内存希望分页，分页可以减少内存的浪费
    0. 段通过页的方式打散
    1. 将内存分成页
    2.针对每个段内存请求，系统一页一页的分配给给这个段


    我的理解，
        概念   虚拟页号对应物理页号     物理页号可以计算出基地址，   物理页号 * 页大小 = 基地址  而 基地址 + 偏移地址 = 物理地址
        
        这保证了内存的充分利用，减少碎片化，每个段可以保存在不连续的页上，在虚拟页上是连续的就行。  
        
